<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=MacRoman"><title>lncRScan</title>

</head>
<body>
<h1>lncRScan - <br>
an approach for filtering possible artefacts and extracting
high-confident lncRNA transcripts from assembled transcripts based on
RNA-Seq
</h1>
<hr>
<h3>Index</h3>
<ul>
<li> <a href="#introduction">Introduction</a></li>
<li> <a href="#tools">Tool used</a></li>
<li> <a href="#input">Input data</a></li>
<li> <a href="#overview">Method overview</a></li>
<li> <a href="#scripts">A set of perl scripts for
realizing lncRScan</a></li>
</ul>
<hr>
<!--introduction-->
<h3><a name="introduction">Introduction</a></h3>
<ul>
lncRScan is part of our method for predicting functional lncRNAs from
RNA-Seq data. It consists of two stages. One is to filter possible
artificial transcripts according to local FPKM scores and number
spliced reads while the other stage is to generate a list of
high-confident lncRNAs according to two criteria, namely exonic length
of transcript and longest ORF length.
</ul>
<hr>
<!--tools-->
<h3><a name="tools">Tools used</a></h3>
<ul>
<li><a href="http://samtools.sourceforge.net/samtools.shtml">Samtools</a>--<br>
A tool for processing SAM/BAM files. </li>
</ul>
<hr>
<!--input-->
<h3><a name="input">Input data</a></h3>
<ul>
<li>combined.gtf--<br>
A GTF file recording gene annotations assembled by ab initio
transcriptome reconstruction like RABT or cufflinks. It is generated by
comparing the predicted transcripts to the reference annotations. </li>
<li>all.bam --<br>
A BAM file combining all mapped reads for KLF1 KO and WT replicates. It
is output by 'Initial assembly'. </li>
<li>reads.number --<br>
Record how many mapped reads in the all.bam
<pre>samtools view -c all.bam &gt; reads.number<br>	</pre>
</li>
<li>assembly-classcode --<br>
A table depicting transcript IDs and their class codes assigned by
cuffcompare
<pre>awk '{print $1\t$4;}' cuffcmp.tracking &gt; assembly-classcode<br>	</pre>
where cuffcmp.tracking is an output file from cuffcompare, which was
run in 'High-confident lncRNAs generation'. </li>
<li>cuffcmp.loci --<br>
A file output by cuffcompare </li>
<li>cuffcmp.assemblies.gtf.tmap --<br>
A file output by cuffcompare </li>
<li><a href="files/non-overlap_list">non-overlap_list</a>
--<br>
</li>
<li><a href="files/candidate_list">candidate_list</a>
--<br>
</li>
</ul>
<hr>
<!--overview-->
<h3><a name="overview">Method overview</a></h3>
<ul>
<li>Part A - to generate a list of assemblies need to be
filtered. Shell commands:<br>
<pre># 1) generate a transcript list according to the local FPKM scores<br>## calculate local FPKM scores for the assembled transcripts<br>sort -k1.4,1.5n -k4,4n -k5,5n combined.gtf &gt; exon.gtf.sorted<br># running following step needs an index file<br>gtf2overlap.pl exon.gtf.sorted &gt; exon.overlap<br>overlap_score.pl exon.overlap all.bam reads.number &gt; subexon.score<br>sum_subexon_scores.pl subexon.score &gt; transcript.scores <br>## generate the list for transcripts need to be filtered according to the local FPKM scores<br>filter_fpkm.pl transcript.scores assembly-classcode &gt; filter_fpkm_list<br><br># 2) generate a transcript list according to the number of spliced reads<br>extract_GTF_class.pl combined.gtf non-overlap_list<br>mv extracted_id non-overlap_id<br>extract_bam_locus.pl cuffcmp.loci non-overlap_id all.bam &gt; candidate.sam<br>gen_junctions.pl candidate.sam &gt; junction.positions<br>sort -k1.4,1.5n -k2,2n -k3,3n junction.positions &gt; junction.positions.sorted<br>count_spliced_junction.pl junction.positions.sorted &gt; junction_spliced.count<br>count_transcript_junctions.pl junction_spliced.count non-overlap.gtf &gt; non-overlap_junctions.counts<br>## generate the list for transcripts need to be filtered according to the number of spliced reads<br>filter_splice.pl non-overlap_junctions.counts &gt; filter_splice_list<br><br># combine above two list of transcripts<br>cat filter_fpkm_list filter_splice_list &gt; filter_list<br>	</pre>
</li>
<li>Part B - to filter assemblies according to the list from
part A. Shell commands:<br>
<pre># generate refined_candidate.gtf<br>extract_GTF_class.pl combined.gtf candidate_list<br>mv extracted.gtf &gt; candidate.gtf<br>filter_GTF_isoform.pl candidate.gtf filter_list &gt;refined_candidate.gtf <br># generate refined_candidate_list<br>extract_GTF_class.pl refined_candidate.gtf candidate_list<br>mv extracted_id &gt; refined_candidate_list <br>	</pre>
</li>
<li>Part C - to generate a list of high-confident lncRNAs.
Shell commands:<br>
<pre># extract transcripts according to the length<br>isoform_new_old.pl refined_candidate.gtf cuffcmp.assemblies.gtf.tmap &gt; refined_candidate.len<br>awk '($2 &gt; 200){print $1;}' refined_candidate.len &gt; extracted_len_candidate_list<br>extract_GTF_isoform.pl refined_candidate.gtf extracted_len_candidate_list &gt; extracted_len_candidate.gtf <br><br># extract transcripts according to the length of longest ORF<br># download sequences(FASTA) of extracted_len_candidate.gtf<br>longorf.pl --input extracted_len_candidate.fasta &gt; extracted_len_candidate.orf<br>candidate_orf.pl extracted_len_candidate.orf &gt; candidate.orf<br>awk '($2 &lt; 300){print $1;}' candidate.orf &gt; high_lncRNA_list<br>	</pre>
</li>
</ul>
<hr>
<!--scripts-->
<h3><a name="scripts">A set of perl scripts for
realizing lncRNA</a></h3>
<ul>
<li><a href="scripts/gtf2overlap.pl">gtf2overlap.pl</a>--<br>
Convert a sorted GTF file to a file containing details of exonic
overlaps </li>
<li><a href="scripts/overlap_score.pl">overlap_score.pl</a>--<br>
Calculate the FPKM score for each exonic overlap </li>
<li><a href="scripts/sum_subexon_scores.pl">sum_subexon_scores.pl</a>--<br>
Sum local FPKM scores for each assembled transcripts </li>
<li><a href="scripts/filter_fpkm.pl">filter_fpkm.pl</a>--<br>
Generate the list for transcripts need to be filtered according to the
local FPKM scores </li>
<li><a href="scripts/extract_bam_locus.pl">extract_bam_locus.pl</a>--<br>
Extract bam according to locus and output a SAM file </li>
<li><a href="scripts/extract_GTF_class.pl">extract_GTF_class.pl</a>--<br>
Extract GTF according to class codes </li>
<li><a href="scripts/gen_junctions.pl">gen_junctions.pl</a>--<br>
List coordinates of spliced junctions </li>
<li><a href="scripts/count_spliced_junction.pl">count_spliced_junction.pl</a>--<br>
Count number of spliced read over junctions </li>
<li><a href="scripts/count_transcript_junctions.pl">count_transcript_junctions.pl</a>--<br>
Count spliced reads at each splicing site of input GTF file </li>
<li><a href="scripts/filter_splice.pl">filter_splice.pl</a>--<br>
Filter artefacts according to number of spliced reads </li>
<li><a href="scripts/isoform_new_old.pl">isoform_new_old.pl</a>--<br>
1) To create a hash connecting old transcript ids given by cufflinks
and new ids given by cuffcompare 2) Then extract length information for
each transcript </li>
<li><a href="scripts/extract_GTF_isoform.pl">extract_GTF_isoform.pl</a>--<br>
Extract transcripts of a GTF according to the transcript ids </li>
<li><a href="scripts/candidate_orf.pl">candidate_orf.pl</a>--<br>
Parse the IDs output from UCSC table browser </li>
<li><a href="scripts/longorf.pl">longorf.pl</a>--<br>
Search the longest ORF for each input FASTA sequences </li>
</ul>
</body></html>